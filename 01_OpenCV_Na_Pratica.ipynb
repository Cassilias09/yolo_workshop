{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97df8f2d",
   "metadata": {},
   "source": [
    "# Open CV Na Prática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f168ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa as bibliotecas necessárias\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ec853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar para exibir imagens lado a lado\n",
    "def show_images_side_by_side(img1, title1, img2, title2, cmap1=None, cmap2=None):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img1, cmap=cmap1)\n",
    "    plt.title(title1)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img2, cmap=cmap2)\n",
    "    plt.title(title2)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6b55d",
   "metadata": {},
   "source": [
    "## 1. Carregando e Visualizando Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf76cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega uma imagem\n",
    "img_path = 'images.jpg' # Substitua pelo caminho da sua imagem\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "\n",
    "# Exibe as dimensões da imagem (altura, largura, canais)\n",
    "print(f\"Dimensões da imagem: {img.shape}\")\n",
    "# Exibe o tipo de dados dos pixels\n",
    "print(f\"Tipo de dados dos pixels: {img.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aee256",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe a imagem usando matplotlib\n",
    "plt.imshow(img)\n",
    "plt.title('Imagem Carregada')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e25c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Exibe a imagem usando matplotlib\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('Imagem Carregada')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae7f12d",
   "metadata": {},
   "source": [
    "## 2. Alterando a Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1ec145",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_rgb[:, :, 0], cmap='gray') # Canal vermelho\n",
    "plt.title('Canal Vermelho')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd593a5f",
   "metadata": {},
   "source": [
    "### 2.1 Redimensionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc777fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensionando a imagem\n",
    "new_width = 300\n",
    "new_height = int(img.shape[0] * (new_width / img.shape[1])) # Manter proporção\n",
    "img_resized = cv2.resize(img, (new_width, new_height))\n",
    "img_resized_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "show_images_side_by_side(img_rgb, 'Imagem Original', img_resized_rgb, f'Imagem Redimensionada para {new_width}x{new_height}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b94e31",
   "metadata": {},
   "source": [
    "### 2.2 Mudando de Escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b038baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo para escala de cinza\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "print(f\"Imagem em escala de cinza. Dimensões: {img_gray.shape}\")\n",
    "show_images_side_by_side(img_rgb, 'Imagem Colorida', img_gray, 'Imagem em Escala de Cinza', cmap1=None, cmap2='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e9865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo para escala HSV\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "show_images_side_by_side(img_rgb, 'Imagem Original', img_hsv, 'Imagem em Escala HSV')\n",
    "\n",
    "# Convertendo para escala YUV\n",
    "img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "show_images_side_by_side(img_rgb, 'Imagem Original', img_yuv, 'Imagem em Escala YUV')\n",
    "\n",
    "# Convertendo para escala LAB\n",
    "img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
    "show_images_side_by_side(img_rgb, 'Imagem Original', img_lab, 'Imagem em Escala LAB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be8670b",
   "metadata": {},
   "source": [
    "### 2.3 Binarização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A binarização converte uma imagem em escala de cinza para uma imagem binária (preto e branco).\n",
    "# Pixels acima de um certo limiar se tornam brancos, e abaixo, pretos.\n",
    "\n",
    "# Primeiro, converta para escala de cinza\n",
    "img_gray_bin = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Exemplo 1: Limiar Fixo\n",
    "threshold_value = 127 # Valor de 0 a 255\n",
    "ret, img_binary_fixed = cv2.threshold(img_gray_bin, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "show_images_side_by_side(img_gray_bin, 'Escala de Cinza', img_binary_fixed, f'Binarização (Limiar Fixo {threshold_value})', cmap1='gray', cmap2='gray')\n",
    "\n",
    "# Exemplo 2: Limiar Otsu (método automático para encontrar o limiar ideal)\n",
    "ret_otsu, img_binary_otsu = cv2.threshold(img_gray_bin, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "show_images_side_by_side(img_gray_bin, 'Escala de Cinza', img_binary_otsu, f'Binarização (Limiar Otsu {ret_otsu})', cmap1='gray', cmap2='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f8493",
   "metadata": {},
   "source": [
    "### 2.4 Suavização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O filtro Gaussiano é usado para suavizar imagens, remover ruídos e reduzir detalhes.\n",
    "# Ele aplica um kernel (matriz de pesos) que simula uma distribuição Gaussiana.\n",
    "\n",
    "# Tamanho do kernel (deve ser ímpar e positivo)\n",
    "kernel_size_small = (5, 5)\n",
    "kernel_size_large = (29, 29)\n",
    "\n",
    "img_gaussian_small = cv2.GaussianBlur(img, kernel_size_small, 0)\n",
    "img_gaussian_large = cv2.GaussianBlur(img, kernel_size_large, 0)\n",
    "\n",
    "img_gaussian_small_rgb = cv2.cvtColor(img_gaussian_small, cv2.COLOR_BGR2RGB)\n",
    "img_gaussian_large_rgb = cv2.cvtColor(img_gaussian_large, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "show_images_side_by_side(img_rgb, 'Original', img_gaussian_small_rgb, f'Gaussiano ({kernel_size_small})')\n",
    "show_images_side_by_side(img_rgb, 'Original', img_gaussian_large_rgb, f'Gaussiano ({kernel_size_large}) - Mais Desfoque')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f88000",
   "metadata": {},
   "source": [
    "### 2.5 Adicionando Informação na Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de53f627",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb[100:200, 100:500] = [255, 0, 0]  # Modifica uma região da imagem\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('Região Modificada da Imagem')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e58ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escrevendo texto na imagem\n",
    "text_img = img.copy() # Cria uma cópia para não alterar a original\n",
    "cv2.putText(text_img, 'Minicurso YOLO', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.circle(text_img, (100, 100), 30, (255, 0, 0), 2) # Desenha um círculo\n",
    "\n",
    "cv2.rectangle(text_img, (150, 150), (250, 250), (0, 0, 255), 2) # Desenha um retângulo\n",
    "\n",
    "text_img_rgb = cv2.cvtColor(text_img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(text_img_rgb)\n",
    "plt.title('Imagem com Texto e Formas')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando a imagem\n",
    "cv2.imwrite('imagem_editada.jpg', text_img)\n",
    "print(\"Imagem editada salva como 'imagem_editada.jpg'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9995092d",
   "metadata": {},
   "source": [
    "## 3. Trabalhando com Vídeos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20088468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o vídeo\n",
    "video_path = 'vehicle-counting.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Loop para ler e exibir alguns frames do vídeo\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read() # ret = True se o frame foi lido com sucesso, frame = o próprio frame\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Exibe o frame (OpenCV windows)\n",
    "    # Para Google Colab ou ambientes sem janela, você pode salvar o frame ou exibi-lo como imagem estática\n",
    "    cv2.imshow('Frame do Video', frame)\n",
    "    \n",
    "    # Espera por uma tecla\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "# Libera o objeto de captura\n",
    "cap.release()\n",
    "# Destrói todas as janelas do OpenCV (se usadas)\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Leitura de frames concluída.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b55da3",
   "metadata": {},
   "source": [
    "### 3.1 Análise de Movimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b890de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A subtração de imagens é uma técnica simples para detectar diferenças entre frames\n",
    "# (ideal para movimento) ou entre duas imagens.\n",
    "# O resultado realça as áreas onde houve mudança.\n",
    "\n",
    "# Para demonstrar, vamos precisar de duas imagens ligeiramente diferentes.\n",
    "# Vamos simular isso usando o mesmo vídeo de antes e pegando dois frames.\n",
    "\n",
    "video_path = 'vehicle-counting.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "# Pular alguns frames para ter alguma mudança\n",
    "for _ in range(int(cap.get(cv2.CAP_PROP_FPS) * 1)): # Pula 1 segundo\n",
    "    ret, _ = cap.read()\n",
    "ret, frame2 = cap.read()\n",
    "\n",
    "cv2.imwrite('frame1.jpg', frame1)\n",
    "show_images_side_by_side(frame1, 'Frame 1', frame2, 'Frame 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ed641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensionar para um tamanho gerenciável\n",
    "frame1 = cv2.resize(frame1, (320, 240))\n",
    "frame2 = cv2.resize(frame2, (320, 240))\n",
    "\n",
    "# Converta os frames para escala de cinza para simplificar a subtração\n",
    "gray_frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "gray_frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Calcule a diferença absoluta entre os frames\n",
    "# cv2.absdiff(src1, src2)\n",
    "# É importante usar absdiff para lidar com valores negativos (diferença de pixels)\n",
    "diff_frame = cv2.absdiff(gray_frame1, gray_frame2)\n",
    "\n",
    "# Opcional: Aplicar um limiar na imagem de diferença para realçar o movimento\n",
    "# Isso cria uma imagem binária onde pixels de movimento são brancos.\n",
    "_, thresholded_diff = cv2.threshold(diff_frame, 30, 255, cv2.THRESH_BINARY) # Limiar de 30\n",
    "\n",
    "# Para melhor visualização, podemos aplicar um desfoque na imagem de diferença antes do threshold\n",
    "# (reduz ruídos e suaviza áreas de movimento)\n",
    "blurred_diff = cv2.GaussianBlur(diff_frame, (21, 21), 0)\n",
    "_, thresholded_blurred_diff = cv2.threshold(blurred_diff, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "show_images_side_by_side(diff_frame, 'Diferença Absoluta (pixels)',\n",
    "                            thresholded_blurred_diff, 'Movimento Detectado (Binarizado)',\n",
    "                            cmap1='gray', cmap2='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6196f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'vehicle-counting.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_writer = cv2.VideoWriter('output_video.mp4', \n",
    "                               cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                               cap.get(cv2.CAP_PROP_FPS), \n",
    "                               (320, 240), isColor=False)\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = cap.read()\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Redimensionar para um tamanho gerenciável\n",
    "    frame1 = cv2.resize(frame1, (320, 240))\n",
    "    frame2 = cv2.resize(frame2, (320, 240))\n",
    "    # Converta os frames para escala de cinza\n",
    "    gray_frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calcule a diferença absoluta entre os frames\n",
    "    diff_frame = cv2.absdiff(gray_frame1, gray_frame2)\n",
    "    # Aplicar um desfoque na imagem de diferença\n",
    "    blurred_diff = cv2.GaussianBlur(diff_frame, (21, 21), 0)\n",
    "    _, thresholded_blurred_diff = cv2.threshold(blurred_diff, 25, 255, cv2.THRESH_BINARY)\n",
    "    # A diferença\n",
    "    cv2.imshow('Movimento Detectado', thresholded_blurred_diff)\n",
    "    \n",
    "    # Escreve o frame processado no vídeo\n",
    "    video_writer.write(thresholded_blurred_diff)\n",
    "    \n",
    "    # Espera por uma tecla\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "# Libera o objeto de captura\n",
    "cap.release()\n",
    "# Destrói todas as janelas do OpenCV (se usadas)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
