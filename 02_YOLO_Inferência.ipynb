{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b8f1e8a",
   "metadata": {},
   "source": [
    "# YOLO na Prática: Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f9b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e422af7",
   "metadata": {},
   "source": [
    "## 1. Carregando o Modelo Pré-Treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ab232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peso padrão do modelo: YOLOv11 treinado no COCO\n",
    "model = YOLO()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efcf677",
   "metadata": {},
   "source": [
    "## 2. Realizando a Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc52ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'frame1.jpg'\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('Imagem de Entrada')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d2a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(source=image_path, conf=0.25, iou=0.7, verbose=False)\n",
    "print(f\"Inferência concluída. Foram encontrados {len(results[0])} objeto(s) detectado(s) na imagem.\")\n",
    "# results é uma lista (mesmo para uma única imagem, pois pode-se passar uma lista de imagens)\n",
    "# Cada elemento da lista é um objeto 'Results'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec80232d",
   "metadata": {},
   "source": [
    "## 3. Analisando o resultado da YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results[0]\n",
    "\n",
    "# result.boxes: Contém as bounding boxes, classes, confianças.\n",
    "boxes = result.boxes\n",
    "print(f\"Tipo de objeto 'boxes': {type(boxes)}\")\n",
    "print(f\"Número de detecções: {len(boxes)}\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "# Exibindo os dados brutos das detecções\n",
    "for detection in boxes:\n",
    "    print(detection.data.cpu().numpy().astype(float))\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce6990",
   "metadata": {},
   "outputs": [],
   "source": [
    "for detection in boxes:\n",
    "    print(f\"Coordenadas: {detection.xyxy.cpu().numpy()}\") # x1, y1, x2, y2\n",
    "    print(f\"Confiança: {detection.conf.cpu().numpy()}\")\n",
    "    print(f\"ID da Classe: {detection.cls.cpu().numpy()}\")\n",
    "    print(f\"Nome da Classe: {model.names[detection.cls.cpu().numpy().astype(int)[0]]}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca269ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotted_image = result.plot() # result.plot() retorna um array NumPy (RGB)\n",
    "\n",
    "plotted_image = cv2.cvtColor(plotted_image, cv2.COLOR_BGR2RGB)  # Converte de BGR para RGB para exibição correta com matplotlib\n",
    "plt.imshow(plotted_image)\n",
    "plt.title('Detecções (Plotadas pelo Ultralytics)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9275313",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_plot = img.copy()\n",
    "\n",
    "# Acessando os nomes das classes diretamente do modelo\n",
    "class_names = model.names\n",
    "\n",
    "# Loopar por cada detecção\n",
    "for box in boxes:\n",
    "    # Coordenadas da bounding box (formato xyxy: x_min, y_min, x_max, y_max)\n",
    "    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "\n",
    "    # Confiança da detecção\n",
    "    confidence = float(box.conf[0].cpu().numpy())\n",
    "\n",
    "    # ID da classe\n",
    "    class_id = int(box.cls[0].cpu().numpy())\n",
    "    class_name = class_names[class_id]\n",
    "\n",
    "    # Filtro de confiança (ex: só mostrar se confiança > 0.5)\n",
    "    if confidence > 0.5:\n",
    "\n",
    "        # Desenhar o retângulo\n",
    "        color = (0, 255, 0) # Verde para BGR\n",
    "        thickness = 10\n",
    "        cv2.rectangle(img_plot, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "        # Colocar o label (nome da classe + confiança)\n",
    "        label = f'{class_name} {confidence:.2f}'\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 2\n",
    "        font_thickness = 2\n",
    "        text_size = cv2.getTextSize(label, font, font_scale, font_thickness)[0]\n",
    "        text_x = x1\n",
    "        text_y = y1 - 10 if y1 - 10 > 10 else y1 + text_size[1] + 10 # Posição do texto\n",
    "        \n",
    "        cv2.rectangle(img_plot, (text_x, text_y - text_size[1] - 5), (text_x + text_size[0] + 5, text_y + 5), color, -1) # Fundo do texto\n",
    "        cv2.putText(img_plot, label, (text_x, text_y), font, font_scale, (0, 0, 0), font_thickness, cv2.LINE_AA) # Texto preto\n",
    "\n",
    "# Exibir a imagem com as detecções plotadas manualmente\n",
    "img_plot_rgb = cv2.cvtColor(img_plot, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_plot_rgb)\n",
    "plt.title('Detecções (Plotadas Manualmente)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a237c7",
   "metadata": {},
   "source": [
    "# 4. Realizando inferência em videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08acad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'vehicle-counting.mp4'\n",
    "output_video_path = 'output_video_yolo.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Propriedades do vídeo\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "print(f\"Resolução do vídeo: {width}x{height}, FPS: {fps}\")\n",
    "\n",
    "# Configurar o VideoWriter para salvar o vídeo com detecções\n",
    "# 'mp4v' é um codec comum para arquivos .mp4\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b705c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = 0\n",
    "while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break # Fim do vídeo ou erro na leitura\n",
    "\n",
    "        results = model.predict(source=frame, conf=0.25, iou=0.7, verbose=False)\n",
    "\n",
    "        annotated_frame = results[0].plot() # results[0] pois processamos um frame por vez\n",
    "\n",
    "        cv2.imshow('Deteccao YOLO', annotated_frame)\n",
    "        \n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break # Pressione 'q' para sair\n",
    "\n",
    "        out.write(annotated_frame)\n",
    "\n",
    "        frame_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf65a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTotal de frames processados: {frame_count}\")\n",
    "cap.release() # Liberar o objeto de captura\n",
    "out.release() # Liberar o objeto de escrita de vídeo\n",
    "cv2.destroyAllWindows() # Fechar todas as janelas\n",
    "print(f\"Vídeo com detecções salvo como '{output_video_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebf29a",
   "metadata": {},
   "source": [
    "## 4.1 Melhorando a inferência em vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9983d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'vehicle-counting.mp4'\n",
    "output_video_path = 'output_video_yolo.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Propriedades do vídeo\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "print(f\"Resolução do vídeo: {width}x{height}, FPS: {fps}\")\n",
    "\n",
    "# Configurar o VideoWriter para salvar o vídeo com detecções\n",
    "# 'mp4v' é um codec comum para arquivos .mp4\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ed4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break # Fim do vídeo ou erro na leitura\n",
    "\n",
    "    results = model.predict(source=frame, conf=0.25, iou=0.7, verbose=False)\n",
    "    \n",
    "    # Acessando os nomes das classes diretamente do modelo\n",
    "    class_names = model.names\n",
    "\n",
    "    boxes = results[0].boxes  # Obter as detecções\n",
    "    # Loopar por cada detecção\n",
    "    for box in boxes:\n",
    "        # Coordenadas da bounding box (formato xyxy: x_min, y_min, x_max, y_max)\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "\n",
    "        # Confiança da detecção\n",
    "        confidence = float(box.conf[0].cpu().numpy())\n",
    "\n",
    "        # ID da classe\n",
    "        class_id = int(box.cls[0].cpu().numpy())\n",
    "        class_name = class_names[class_id]\n",
    "\n",
    "        # Filtro de confiança (ex: só mostrar se confiança > 0.5)\n",
    "        if confidence > 0.5:\n",
    "\n",
    "            # Desenhar o retângulo\n",
    "            color = (0, 255, 0) # Verde para BGR\n",
    "            thickness = 10\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "            # Colocar o label (nome da classe + confiança)\n",
    "            label = f'{class_name} {confidence:.2f}'\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 2\n",
    "            font_thickness = 2\n",
    "            text_size = cv2.getTextSize(label, font, font_scale, font_thickness)[0]\n",
    "            text_x = x1\n",
    "            text_y = y1 - 10 if y1 - 10 > 10 else y1 + text_size[1] + 10 # Posição do texto\n",
    "            \n",
    "            cv2.rectangle(frame, (text_x, text_y - text_size[1] - 5), (text_x + text_size[0] + 5, text_y + 5), color, -1) # Fundo do texto\n",
    "            cv2.putText(frame, label, (text_x, text_y), font, font_scale, (0, 0, 0), font_thickness, cv2.LINE_AA) # Texto preto\n",
    "\n",
    "    cv2.imshow('Deteccao YOLO', frame)\n",
    "    \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break # Pressione 'q' para sair\n",
    "    \n",
    "    out.write(annotated_frame)\n",
    "    frame_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029cf63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTotal de frames processados: {frame_count}\")\n",
    "cap.release() # Liberar o objeto de captura\n",
    "out.release() # Liberar o objeto de escrita de vídeo\n",
    "cv2.destroyAllWindows() # Fechar todas as janelas\n",
    "print(f\"Vídeo com detecções salvo como '{output_video_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
